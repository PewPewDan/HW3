---
title: "HW3"
output: github_document
date: "2023-03-20"
---

```{r setup, include=FALSE}


library(tidyverse)
library(mosaic)
library(foreach)
library(modelr)
library(rsample)
library(knitr)

```

## Green Buildings Prediction

### Using basic regression and step functions

For the purposes of this model, we chose to include 12 elements/element combinations for our prediction of revenue.  The most important to answer the question is green rating, which tells if the building in question either LEED- or EnergyStar-certified.  We also chose to include variables measuring utility cost, as well as if those costs are placed on the tenant or the landlord.  We declined to include rent and leasing rate because our outcome variable, revenue, is the product of those two variables.  As such, including them in the model as independent variables would result in perfect multicollinearity.  We also looked at measures such as the age, renovations, and amenities near the building.  The initial lm model that provided reasonable RMSE was: 

$Revenue_i$ =  $\beta_0$ + $\beta_1BuildingSize$ + $\beta_2EmploymentGrowth$ + $\beta_3Age$ + $\beta_4Renovated$ + $\beta_5Renovated*Age$ + $\beta_6GreenRating$ + $\beta_7Amenitie$s + $\beta_8DaysUtilitesUsed$ + $\beta_9GasCost$ + $\{beta_10}ElectricityCost$ + $\beta_{11}UtilitiesPaidBy $

```{r, include = FALSE}
gb = read_csv("greenbuildings.csv")
gb = drop_na(gb)
gb = gb %>%
  mutate(revenue = leasing_rate*Rent)



# Split into training and testing sets
gb_split = initial_split(gb, prop = 0.8)
gb_train = training(gb_split)
gb_test = testing(gb_split)

```

Starting with this base model, we measured the RMSE using a training/test split on the data.  Then, in order to test different variations of the model, we used step() to measure various interactions on the data.  The coefficients that were significant and therefore included in the model are shown below, as well as their coefficients.  The RMSE of this model is lower than just the base model, but it still seems as though we could do better. In order to test this, we move into forest and boosted models. 

```{r, include = FALSE}

# baseline medium model with 12 main effects
lm_medium = lm(revenue ~ size + empl_gr + stories + age + renovated + age*renovated + green_rating + amenities + total_dd_07 - Gas_Costs - 
                 Electricity_Costs + net, data = gb_train)




# stepwise selection
# note that we start with a reasonable guess
lm_step = step(lm_medium, 
			scope=~(.)^2)
# the scope statement says:
# "consider all two-way interactions for everything in lm_medium (.)

# what variables are included?

```

```{r, echo = FALSE}
getCall(lm_step)
coef(lm_step)

med_error = rmse(lm_medium,gb_test)
step_error = rmse(lm_step, gb_test)

```
### Using Tree/Boosted Models

In order to use the tree modelling, we measure a random forest model using the same base model that we measured above.  We also tested a boosted model with an interaction depth of 4 and 200 trees.  From these models, it is clear that the model with the lowest RMSE is the random forest model.  A table showing the RMSE of each prediciton method is shown below.  

```{r forest, include = FALSE}
##install.packages("gbm")
library(gbm)
urlPackage <- "https://cran.r-project.org/src/contrib/Archive/randomForest/randomForest_4.6-12.tar.gz"
##install.packages(urlPackage, repos=NULL, type="source") 
library(randomForest)

forest_error <- list()
boost_error <- list()

for (i in 1:2){
rforest <- randomForest(revenue ~ size + empl_gr + stories + age + renovated + age*renovated + green_rating + amenities + total_dd_07 - Gas_Costs - 
                 Electricity_Costs + net, data = gb_train, importance = TRUE)
  
  forest_error[[i]] <- rmse(rforest, gb_test)
  

boost <- gbm(revenue ~ size + empl_gr + stories + age + renovated + age*renovated + green_rating + amenities + total_dd_07 - Gas_Costs - 
                 Electricity_Costs + net, data = gb_train,
                 interaction.depth= 4, n.trees=200, shrinkage=.05)
  
  
 boost_error[[i]] <- rmse(boost, gb_test)
}

rmse_forest <- round(mean(unlist(forest_error)), 2)
rmse_boost <- round(mean(unlist(boost_error)), 2)

```


```{r, echo = FALSE}
library(knitr)
my_data = data.frame(med_error, step_error, boost_error, forest_error)

kable(my_data)


```

### Partial Dependence - The Importance of the Green Rating

Fron this plot, it does appear as though green rating does cause an increase in revenue - however, a rating of 1 only increases revenue about $100 from a rating of 0, so it is clearly not the most important variables.

``` {r, echo = FALSE, warning=FALSE, message=FALSE}

library(pdp)
p = pdp::partial(rforest, pred.var = 'green_rating', las = 1)

plot(p,type = "l", xlab = "Green Rating", ylab = "Revenue", main = "Predicted Revenue by Green Rating")

```



The following variable importance plot helps us measure which variables are very important in terms of prediction.  In terms of increasing the RMSE, age, size, employment growth, and days that utlities were used are very important to predict this model.  We can also see that green rating is one of the less important prediction variables. 

### Conclusion

From these test, it seems as though the forest model provided the best RMSE in terms of of overall revenue prediciton.  The green rating of a building does not impact the revenue very much at all. 



``` {r, echo=FALSE, warning=FALSE, message=FALSE}
varImpPlot(rforest)
```

